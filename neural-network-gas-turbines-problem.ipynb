{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load the data from the CSV file\ndata = pd.read_csv('gas_turbines.csv')\n\n# Explore the data\nprint(data.head())\n\n# Visualize univariate distributions with histograms\ndata.hist(figsize=(12, 10))\nplt.suptitle('Univariate Distributions')\nplt.show()\n\n# Visualize bivariate relationships with scatter plots\nsns.pairplot(data, corner=True)\nplt.suptitle('Bivariate Relationships')\nplt.show()\n\n# Split the data into features (X) and target variable (y)\nX = data.drop(['TEY'], axis=1)\ny = data['TEY']\n\n# Scale the features to a specific range (e.g., 0-1)\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Create a neural network model\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1))\n\n# Compile the model\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n# Define early stopping to prevent overfitting\nearly_stop = EarlyStopping(monitor='val_loss', patience=10)\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop])\n\n# Visualize training history\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training History')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Reverse the scaling on the predicted and actual values\ny_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()  # Adjusting the reshaping here\ny_test = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint('Mean Squared Error:', mse)\nprint('R^2 Score:', r2)\n\n","metadata":{},"execution_count":null,"outputs":[]}]}